{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Seq2Seq?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seq2Seq is a neural network architecture that is used for sequence to sequence problems. It is used for tasks like machine translation, text summarization, speech recognition, etc. It is a neural network architecture that consists of two recurrent neural networks (RNNs) connected to each other. The first RNN is called the encoder and the second RNN is called the decoder. The encoder RNN reads the input sequence and the decoder RNN generates the output sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Encoder-decode-structure](https://miro.medium.com/max/828/1*YAPAHVYhsaEARYz45bO0Gg.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the information of the input sentence is extracted into a dense vector by the encoder. The encoded information is stored in the hidden state of the encoder RNN. \n",
    "\n",
    "![](https://miro.medium.com/max/640/1*pQwlJ5c2XOLGg0_-KUJ3MQ.jpeg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decoder do decoding/translating the output of the encoder. It uses this hidden state vector to generate the output sequence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/828/1*rkgcxYFzLZjz7o6hz3FsQw.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/828/1*bjSD5iFeP5vbSzQ0MuAf5w.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Assume we have Source sentence $S^{(i)}$ and the target translation $T^{(i)}. We want to maximize\n",
    "\n",
    "$$\\sum_i \\log P(T^{(i)}|S^{(i)})$$\n",
    "\n",
    "- Compute the hidden state $h_t$ for each word (time step) in the input sentence $S^{(i)}$ using the RNN.\n",
    "- Use it as the input hidden state to the decoder RNN\n",
    "- Compute the $\\hat{y_t}$ for every time step in the target sequence\n",
    "- Multiply the probs of the actual outputs in the target sequence\n",
    "- Finally, we get $$argmax_TP(T \\mid S)$$ and $T$ is the target sequence (translated sentence)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do we need Seq2Seq?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine translation is a task that you translate a sentence from one language to another. For example, you can translate a sentence from English to French. This task is very difficult because there are many words in a language that have multiple meanings. For example, the word “bank” can mean a financial institution or a river bank. This is a very difficult task for a machine to do. Seq2Seq is used to solve this problem.\n",
    "\n",
    "Encoder encodes the input sentence and pass the decoded information into the deocder. The decoder generates the output sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image captioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, we encode the image into a vector and pass it to the decoder. The decoder generates the caption for the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img-captioning](https://miro.medium.com/max/1400/1*6BFOIdSHlk24Z3DFEakvnQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Seq2Seq in Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Seq2Seq](https://miro.medium.com/max/828/1*ravhj1M9KFg0u77aDqM_MQ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (d:\\users\\trmin\\miniconda3\\envs\\vietocr\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (d:\\users\\trmin\\miniconda3\\envs\\vietocr\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (d:\\users\\trmin\\miniconda3\\envs\\vietocr\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (d:\\users\\trmin\\miniconda3\\envs\\vietocr\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (d:\\users\\trmin\\miniconda3\\envs\\vietocr\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (d:\\users\\trmin\\miniconda3\\envs\\vietocr\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gdown\n",
    "\n",
    "if os.path.exists('/content/'):\n",
    "    # os.system('!gdown 1ty8k-omlU3zvSUemx2gvBaEQWAWZAQ1C')\n",
    "    # os.system(\"!gdown \")\n",
    "    gdown.download(\"https://drive.google.com/file/d/1ty8k-omlU3zvSUemx2gvBaEQWAWZAQ1C\", output='./train.en')\n",
    "    gdown.download(\"https://drive.google.com/file/d/1mzDv83hvTlsLNSg7XNIIFLub36YVOf6u\", output='./train.vi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import unicodedata\n",
    "from io import open\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {}\n",
    "        self.special_tokens = [\"<sos>\", \"<eos>\", \"<unk>\", \"<pad>\"]\n",
    "        for token in self.special_tokens:\n",
    "            self.word2index[token] = len(self.word2index)\n",
    "            self.index2word[len(self.index2word)] = token\n",
    "        self.n_words = len(self.index2word)  # Count SOS, EOS, UNK, and special tokens\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    # s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def readLangs(filename, lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    from_lang = None\n",
    "    with open(f'{filename}.{lang1}', 'r+', encoding='utf8') as f:\n",
    "        from_lang = f.read().strip().split('\\n')\n",
    "        \n",
    "    to_lang = None\n",
    "    with open(f'{filename}.{lang2}', 'r+', encoding='utf8') as f:\n",
    "        to_lang = f.read().strip().split('\\n')\n",
    "        \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = list(zip(from_lang, to_lang))\n",
    "    # pairs = [[normalizeString(s) for s in l] for l in pairs]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 133317 sentence pairs\n",
      "Trimmed to 133311 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "en 54152\n",
      "vi 25610\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 512\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "def prepareData(filename, lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(filename, lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('./train-en-vi/train', 'en', 'vi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length of input: 485\n",
      "max length of output: 481\n"
     ]
    }
   ],
   "source": [
    "print(f'max length of input: {max([len(pair[0].split(\" \")) for pair in pairs])}')\n",
    "print(f'max length of output: {max([len(pair[1].split(\" \")) for pair in pairs])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs, test_pairs = train_test_split(pairs, test_size=0.2, random_state=42)\n",
    "\n",
    "class MTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, pairs, lang1, lang2, max_length=MAX_LENGTH):\n",
    "        self.pairs = pairs\n",
    "        self.lang1 = lang1\n",
    "        self.lang2 = lang2\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        source, target = self.pairs[idx]\n",
    "        \n",
    "        source = [\"<sos>\"] + source.split(\" \") + [\"<eos>\"]\n",
    "        source_ids = [self.lang1.word2index.get(word, self.lang1.word2index[\"<unk>\"]) for word in source]\n",
    "        if len(source_ids) < MAX_LENGTH:\n",
    "            source_ids += [self.lang1.word2index[\"<pad>\"]] * (MAX_LENGTH - len(source_ids))\n",
    "        elif len(source_ids) > MAX_LENGTH:\n",
    "            source_ids = source_ids[:MAX_LENGTH]\n",
    "        source_ids = torch.tensor(source_ids, dtype=torch.long)\n",
    "        \n",
    "        target = [\"<sos>\"] + target.split(\" \") + [\"<eos>\"]\n",
    "        target_ids = [self.lang2.word2index.get(word, self.lang2.word2index[\"<unk>\"]) for word in target]\n",
    "        if len(target_ids) < MAX_LENGTH:\n",
    "            target_ids += [self.lang2.word2index[\"<pad>\"]] * (MAX_LENGTH - len(target_ids))\n",
    "        elif len(target_ids) > MAX_LENGTH:\n",
    "            target_ids = target_ids[:MAX_LENGTH]\n",
    "        target_ids = torch.tensor(target_ids, dtype=torch.long)\n",
    "        \n",
    "        return source_ids, target_ids\n",
    "    \n",
    "train_dataset = MTDataset(train_pairs, input_lang, output_lang)\n",
    "test_dataset = MTDataset(test_pairs, input_lang, output_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> In fact , nothing even actually comes close to our ability to restore hearing . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "<sos> Trên thực tế , chẳng có cái gì thật sự đạt được đến khả năng hồi phục thính giác . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> "
     ]
    }
   ],
   "source": [
    "tmp = 12\n",
    "for word in train_dataset[tmp][0]:\n",
    "    print(input_lang.index2word[word.item()], end=' ')\n",
    "print()\n",
    "\n",
    "for word in train_dataset[tmp][1]:\n",
    "    print(output_lang.index2word[word.item()], end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, dropout_p):\n",
    "        \"\"\"\n",
    "            :param input_size: size of input vocabulary\n",
    "            :param embedding_size: size of embedding layer\n",
    "            :param hidden_size: size of hidden layer\n",
    "            :param num_layers: number of layers\n",
    "            :param dropout_p: dropout probability\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.embedding = nn.Embedding(input_size, embedding_dim=embedding_size)\n",
    "        self.rnn = nn.LSTM(\n",
    "            embedding_size, \n",
    "            hidden_size, \n",
    "            num_layers,\n",
    "            dropout=dropout_p\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "            :param x: input of shape (seq_length, batch_size)\n",
    "            :return: output of shape (seq_length, batch_size, hidden_size)\n",
    "            :return: hidden of shape (num_layers, batch_size, hidden_size)\n",
    "        \"\"\"\n",
    "        # embedding shape: (seq_length, batch_size, embedding_size)\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        output, (hidden, cell) = self.rnn(embedding)\n",
    "        \n",
    "        return hidden, cell\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, dropout_p):\n",
    "        \"\"\"\n",
    "            :param input_size: size of target vocabulary\n",
    "            :param embedding_size: size of embedding layer\n",
    "            :param hidden_size: size of hidden layer (same as encoder)\n",
    "            :param output_size: size of output layer (same as target vocabulary)\n",
    "            :param num_layers: number of layers\n",
    "            :param dropout_p: dropout probability\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.embedding = nn.Embedding(input_size, embedding_dim=embedding_size)\n",
    "        \n",
    "        self.rnn = nn.LSTM(\n",
    "            embedding_size,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            dropout=dropout_p\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        \"\"\"\n",
    "            :param x: input of shape (batch_size)\n",
    "            :param hidden: hidden state of shape (num_layers, batch_size, hidden_size)\n",
    "            :param cell: cell state of shape (num_layers, batch_size, hidden_size)\n",
    "        \"\"\"\n",
    "        \n",
    "        # shape of x: (batch_size) => (1, batch_size) because we are processing one word at a time\n",
    "        x = x.unsqueeze(0)\n",
    "        \n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (1, batch_size, embedding_size)\n",
    "        \n",
    "        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
    "        # outputs shape: (1, batch_size, hidden_size)\n",
    "        \n",
    "        predictions = self.fc(outputs)\n",
    "        # shape of predictions: (1, batch_size, output_size)\n",
    "        \n",
    "        predictions = predictions.squeeze(0)\n",
    "        \n",
    "        return predictions, hidden, cell\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
    "        \"\"\"\n",
    "            :param source: source sentence of shape (src_len, batch_size)\n",
    "            :param target: target sentence of shape (trg_len, batch_size)\n",
    "            :param teacher_forcing_ratio: probability of using teacher forcing\n",
    "        \"\"\"\n",
    "        batch_size = source.shape[1] # shape: (src_len, batch_size)\n",
    "        target_length = target.shape[0]\n",
    "        target_vocab_size = self.decoder.output_size\n",
    "        \n",
    "        # tensor to store decoder outputs one word at a time\n",
    "        outputs = torch.zeros(target_length, batch_size, target_vocab_size).to(device)\n",
    "        \n",
    "        # last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        hidden, cell = self.encoder(source)\n",
    "        \n",
    "        # Get start token <sos> for each batch\n",
    "        x = target[0]\n",
    "        \n",
    "        for t in range(1, target_length):\n",
    "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
    "            \n",
    "            # output in shape (batch_size, target_vocab_size)\n",
    "            outputs[t] = output \n",
    "\n",
    "            # get index of highest probability word in target vocabulary\n",
    "            best_guess = output.argmax(1)\n",
    "            \n",
    "            # use teacher forcing\n",
    "            x = target[t] if random.random() < teacher_forcing_ratio else best_guess\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/20]\n",
      "Translated example sentence: \n",
      " ['Randers', '16', '16', 'Hopskin', 'thàm', 'Suarez', 'triết', 'nhiều', 'Arusha', 'khan', 'Perceptive', 'Perceptive', 'O`Toole', 'Motetema', 'Kết', 'Garmin', 'Garmin', 'ngào', 'leatherjacket', 'leatherjacket', 'leatherjacket', 'click', 'click', 'Miebach', 'Vardi', 'đoái', 'đoái', 'Leikei', 'rhinovirus', 'click', 'Bambir', 'nhiếc', 'nhiếc', 'tuệ', 'Cleveland', 'Cleveland', 'Đề', 'giới.Tại', 'Todagin', 'Thà', 'click', 'click', 'Vardi', 'Riley', 'mắng', 'mắng', 'biriani', 'biriani', 'ngao', 'Cornwall']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f90ef694bf4fe0aff147652e900cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13331 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\reimplementation-of-deep-learning-models\\PyTorch\\Machine Translation Seq2Seq LSTM\\Seq2Seq.ipynb Cell 34\u001b[0m in \u001b[0;36m<cell line: 53>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/reimplementation-of-deep-learning-models/PyTorch/Machine%20Translation%20Seq2Seq%20LSTM/Seq2Seq.ipynb#X45sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/reimplementation-of-deep-learning-models/PyTorch/Machine%20Translation%20Seq2Seq%20LSTM/Seq2Seq.ipynb#X45sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, target)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Projects/reimplementation-of-deep-learning-models/PyTorch/Machine%20Translation%20Seq2Seq%20LSTM/Seq2Seq.ipynb#X45sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/reimplementation-of-deep-learning-models/PyTorch/Machine%20Translation%20Seq2Seq%20LSTM/Seq2Seq.ipynb#X45sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(model\u001b[39m.\u001b[39mparameters(), max_norm\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/reimplementation-of-deep-learning-models/PyTorch/Machine%20Translation%20Seq2Seq%20LSTM/Seq2Seq.ipynb#X45sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32md:\\Users\\trmin\\miniconda3\\envs\\vietocr\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32md:\\Users\\trmin\\miniconda3\\envs\\vietocr\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "\n",
    "def train(num_epochs, learning_rate, batch_size, device, ):\n",
    "    raise NotImplementedError\n",
    "\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "batch_size = 8\n",
    "\n",
    "load_model = False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_size_encoder = len(input_lang)\n",
    "input_size_decoder = len(output_lang)\n",
    "output_size = len(output_lang)\n",
    "encoder_embedding_size = 256\n",
    "decoder_embedding_size = 256\n",
    "hidden_size = 512\n",
    "num_layers = 2\n",
    "enc_dropout = 0.5\n",
    "dec_dropout = 0.5\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "\n",
    "writer = SummaryWriter(f'runs/loss_plot')\n",
    "step = 0\n",
    "\n",
    "encoder = Encoder(\n",
    "    input_size_encoder, \n",
    "    encoder_embedding_size, \n",
    "    hidden_size, \n",
    "    num_layers, \n",
    "    enc_dropout).to(device)\n",
    "\n",
    "decoder = Decoder(\n",
    "    input_size_decoder,\n",
    "    decoder_embedding_size,\n",
    "    hidden_size,\n",
    "    output_size,\n",
    "    num_layers,\n",
    "    dec_dropout).to(device)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder).to(device)\n",
    "\n",
    "pad_idx = output_lang.word2index['<pad>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# if load_model:\n",
    "#     load_checkpoint(torch.load())\n",
    "example = \"I am a student so I go to school every day .\"\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch [{epoch}/{num_epochs}]')\n",
    "    \n",
    "    checkpoint = {'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict()}\n",
    "    \n",
    "    model.eval()\n",
    "    translated_sentence = translate_sentence(model, example, input_lang, output_lang, device, max_length=50)\n",
    "    print(f'Translated example sentence: \\n {translated_sentence}')\n",
    "\n",
    "    model.train()\n",
    "    bar = tqdm(train_loader)\n",
    "    for batch_idx, batch in enumerate(bar):\n",
    "        inp_data = batch[0].to(device)\n",
    "        target = batch[1].to(device)\n",
    "        \n",
    "        output = model(inp_data, target)\n",
    "        # output shape: (target_length, batch_size, target_vocab_size)\n",
    "        \n",
    "        # reshape output and target to calculate loss\n",
    "        # ignoring the <sos> token\n",
    "        output = output[1:].reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        optimizer.step()\n",
    "        \n",
    "        writer.add_scalar('Training loss', loss, global_step=step)\n",
    "        bar.set_description(f'Epoch [{epoch}/{num_epochs}]')\n",
    "        bar.set_postfix(loss=loss.item())\n",
    "        bar.update()\n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "    \n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "trainIters(encoder1, decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateRandomly(encoder1, decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \n",
    "- https://medium0.com/@saikrishna4820/lstm-language-translation-18c076860b23\n",
    "- https://towardsdatascience.com/what-is-an-encoder-decoder-model-86b3d57c5e1a\n",
    "- https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('vietocr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "60461c33adb2bc2914643cf4ede82f2d271bf481ae2ac16ee103032447a7c5d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
